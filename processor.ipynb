{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6253ef2e",
   "metadata": {},
   "source": [
    "# nimslo auto-aligning gif processor\n",
    "\n",
    "welcome to the nimslo magic! this notebook will help you create perfectly aligned gifs from your nimslo film shots.\n",
    "\n",
    "## quick test - verify packages loaded correctly\n",
    "\n",
    "run the cell below to make sure everything is working:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that all packages load correctly\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "print(\"üéâ all packages loaded successfully!\")\n",
    "print(f\"üì¶ opencv version: {cv2.__version__}\")\n",
    "print(f\"üî¢ numpy version: {np.__version__}\")\n",
    "print(\"‚úÖ ready to process nimslo images!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "547612d2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## next steps\n",
    "\n",
    "if the test above worked, you're all set! \n",
    "\n",
    "the full nimslo processing pipeline code was built earlier but got deleted. you can either:\n",
    "\n",
    "1. **rebuild the pipeline** - i can recreate all the processing functions\n",
    "2. **start with basics** - load some images and experiment manually  \n",
    "3. **sync from remote** - if you have the full notebook on your remote server\n",
    "\n",
    "let me know which approach you'd prefer!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db653584",
   "metadata": {},
   "source": [
    "# nimslo auto-aligning gif processor\n",
    "\n",
    "welcome to the nimslo magic! this notebook takes your developed nimslo film shots and creates perfectly aligned gifs using some computer vision wizardry.\n",
    "\n",
    "## what we're doing:\n",
    "- load and select 4-6 images from your nimslo batch\n",
    "- use a simple gui to pick reference points for alignment\n",
    "- leverage cnn-based image alignment \n",
    "- match histograms for consistent exposure\n",
    "- export smooth aligned gifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.widgets import Button, RectangleSelector\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for gif creation\n",
    "from PIL import Image as PILImage\n",
    "import imageio\n",
    "\n",
    "# for deep learning alignment (we'll use opencv's built-in features first, then upgrade to CNN if needed)\n",
    "from sklearn.feature_extraction import image\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# jupyter display magic\n",
    "from IPython.display import display, HTML, Image as IPImage\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"üöÄ all imports loaded successfully!\")\n",
    "print(\"üì¶ make sure you have: opencv-python, pillow, matplotlib, scikit-learn, imageio\")\n",
    "print(\"üí° tip: install with `pip install opencv-python pillow matplotlib scikit-learn imageio ipywidgets`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NimsloProcessor:\n",
    "    \"\"\"\n",
    "    main class for processing nimslo images into aligned gifs\n",
    "    handles image loading, alignment, histogram matching, and gif export\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.images = []\n",
    "        self.image_paths = []\n",
    "        self.reference_points = []\n",
    "        self.aligned_images = []\n",
    "        self.matched_images = []\n",
    "        self.crop_box = None\n",
    "        \n",
    "    def load_images(self, folder_path=None):\n",
    "        \"\"\"load images from folder or file dialog\"\"\"\n",
    "        if folder_path is None:\n",
    "            root = tk.Tk()\n",
    "            root.withdraw()\n",
    "            folder_path = filedialog.askdirectory(title=\"select nimslo batch folder\")\n",
    "            root.destroy()\n",
    "        \n",
    "        if not folder_path:\n",
    "            print(\"‚ùå no folder selected\")\n",
    "            return False\n",
    "            \n",
    "        # look for common image formats\n",
    "        extensions = ['*.jpg', '*.jpeg', '*.png', '*.tiff', '*.tif']\n",
    "        image_files = []\n",
    "        \n",
    "        for ext in extensions:\n",
    "            image_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "            image_files.extend(glob.glob(os.path.join(folder_path, ext.upper())))\n",
    "        \n",
    "        image_files.sort()  # ensure consistent ordering\n",
    "        \n",
    "        if len(image_files) < 4:\n",
    "            print(f\"‚ùå need at least 4 images, found {len(image_files)}\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"üìÅ found {len(image_files)} images\")\n",
    "        \n",
    "        # load first 6 images max (nimslo typically has 4)\n",
    "        selected_files = image_files[:6]\n",
    "        self.image_paths = selected_files\n",
    "        self.images = []\n",
    "        \n",
    "        for i, path in enumerate(selected_files):\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                self.images.append(img_rgb)\n",
    "                print(f\"‚úÖ loaded image {i+1}: {os.path.basename(path)} ({img_rgb.shape})\")\n",
    "            else:\n",
    "                print(f\"‚ùå failed to load: {path}\")\n",
    "        \n",
    "        return len(self.images) >= 4\n",
    "    \n",
    "    def show_images(self, images=None, title=\"nimslo batch\"):\n",
    "        \"\"\"display loaded images in a grid\"\"\"\n",
    "        if images is None:\n",
    "            images = self.images\n",
    "            \n",
    "        if not images:\n",
    "            print(\"‚ùå no images to display\")\n",
    "            return\n",
    "            \n",
    "        n_images = len(images)\n",
    "        cols = min(4, n_images)\n",
    "        rows = (n_images + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 4*rows))\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "        \n",
    "        if rows == 1:\n",
    "            axes = [axes] if cols == 1 else axes\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "        for i, img in enumerate(images):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"frame {i+1}\")\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        # hide unused subplots\n",
    "        for i in range(n_images, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# create processor instance\n",
    "processor = NimsloProcessor()\n",
    "print(\"üîß nimslo processor initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveCropper:\n",
    "    \"\"\"interactive gui for selecting crop area and reference points\"\"\"\n",
    "    \n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.crop_coords = None\n",
    "        self.reference_points = []\n",
    "        self.fig = None\n",
    "        self.ax = None\n",
    "        self.selector = None\n",
    "        \n",
    "    def on_crop_select(self, eclick, erelease):\n",
    "        \"\"\"callback for crop selection\"\"\"\n",
    "        x1, y1 = int(eclick.xdata), int(eclick.ydata)\n",
    "        x2, y2 = int(erelease.xdata), int(erelease.ydata)\n",
    "        \n",
    "        # ensure proper ordering\n",
    "        x1, x2 = min(x1, x2), max(x1, x2)\n",
    "        y1, y2 = min(y1, y2), max(y1, y2)\n",
    "        \n",
    "        self.crop_coords = (x1, y1, x2, y2)\n",
    "        print(f\"üìê crop selected: ({x1}, {y1}) to ({x2}, {y2})\")\n",
    "        \n",
    "    def on_click(self, event):\n",
    "        \"\"\"callback for reference point selection\"\"\"\n",
    "        if event.inaxes != self.ax:\n",
    "            return\n",
    "            \n",
    "        if event.button == 1 and event.dblclick:  # double click\n",
    "            x, y = int(event.xdata), int(event.ydata)\n",
    "            self.reference_points.append((x, y))\n",
    "            \n",
    "            # plot the point\n",
    "            self.ax.plot(x, y, 'ro', markersize=8, markeredgecolor='white', markeredgewidth=2)\n",
    "            self.fig.canvas.draw()\n",
    "            \n",
    "            print(f\"üìç reference point {len(self.reference_points)}: ({x}, {y})\")\n",
    "            \n",
    "    def select_crop_and_reference(self):\n",
    "        \"\"\"interactive selection of crop area and reference point\"\"\"\n",
    "        print(\"üéØ crop selection mode:\")\n",
    "        print(\"   - drag to select crop area\")\n",
    "        print(\"   - double-click to add reference points\")\n",
    "        print(\"   - close window when done\")\n",
    "        \n",
    "        self.fig, self.ax = plt.subplots(figsize=(12, 8))\n",
    "        self.ax.imshow(self.image)\n",
    "        self.ax.set_title(\"select crop area (drag) and reference points (double-click)\")\n",
    "        \n",
    "        # rectangle selector for cropping\n",
    "        self.selector = RectangleSelector(\n",
    "            self.ax, self.on_crop_select,\n",
    "            useblit=True, button=[1], minspanx=50, minspany=50,\n",
    "            spancoords='pixels', interactive=True\n",
    "        )\n",
    "        \n",
    "        # click handler for reference points\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.on_click)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return self.crop_coords, self.reference_points\n",
    "\n",
    "def add_crop_selection_to_processor():\n",
    "    \"\"\"add cropping functionality to the main processor\"\"\"\n",
    "    \n",
    "    def select_crop_and_reference(self, image_index=0):\n",
    "        \"\"\"select crop area and reference points on specified image\"\"\"\n",
    "        if not self.images:\n",
    "            print(\"‚ùå no images loaded\")\n",
    "            return False\n",
    "            \n",
    "        if image_index >= len(self.images):\n",
    "            print(f\"‚ùå image index {image_index} out of range\")\n",
    "            return False\n",
    "            \n",
    "        cropper = InteractiveCropper(self.images[image_index])\n",
    "        crop_coords, ref_points = cropper.select_crop_and_reference()\n",
    "        \n",
    "        if crop_coords:\n",
    "            self.crop_box = crop_coords\n",
    "            print(f\"‚úÖ crop area saved: {crop_coords}\")\n",
    "        \n",
    "        if ref_points:\n",
    "            self.reference_points = ref_points\n",
    "            print(f\"‚úÖ {len(ref_points)} reference points saved\")\n",
    "            \n",
    "        return crop_coords is not None or ref_points\n",
    "    \n",
    "    # add method to processor class\n",
    "    NimsloProcessor.select_crop_and_reference = select_crop_and_reference\n",
    "\n",
    "# add the functionality\n",
    "add_crop_selection_to_processor()\n",
    "print(\"üé® interactive cropping functionality added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999365e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAligner:\n",
    "    \"\"\"handles the alignment of images using computer vision techniques\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialize feature detectors (try SIFT first, fall back to ORB)\n",
    "        try:\n",
    "            self.sift = cv2.SIFT_create()\n",
    "            self.feature_detector = 'sift'\n",
    "            print(\"üîç using SIFT feature detector\")\n",
    "        except:\n",
    "            self.sift = cv2.ORB_create(nfeatures=1000)\n",
    "            self.feature_detector = 'orb'\n",
    "            print(\"üîç using ORB feature detector (SIFT not available)\")\n",
    "            \n",
    "        # matcher\n",
    "        if self.feature_detector == 'sift':\n",
    "            self.matcher = cv2.FlannBasedMatcher()\n",
    "        else:\n",
    "            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    def detect_and_match_features(self, img1, img2, ratio_threshold=0.7):\n",
    "        \"\"\"detect features and find matches between two images\"\"\"\n",
    "        # convert to grayscale\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # detect keypoints and descriptors\n",
    "        kp1, des1 = self.sift.detectAndCompute(gray1, None)\n",
    "        kp2, des2 = self.sift.detectAndCompute(gray2, None)\n",
    "        \n",
    "        if des1 is None or des2 is None:\n",
    "            print(\"‚ùå no features detected\")\n",
    "            return [], [], []\n",
    "            \n",
    "        # match features\n",
    "        if self.feature_detector == 'sift':\n",
    "            matches = self.matcher.knnMatch(des1, des2, k=2)\n",
    "            # apply ratio test\n",
    "            good_matches = []\n",
    "            for match_pair in matches:\n",
    "                if len(match_pair) == 2:\n",
    "                    m, n = match_pair\n",
    "                    if m.distance < ratio_threshold * n.distance:\n",
    "                        good_matches.append(m)\n",
    "        else:\n",
    "            matches = self.matcher.match(des1, des2)\n",
    "            good_matches = sorted(matches, key=lambda x: x.distance)[:50]\n",
    "        \n",
    "        return kp1, kp2, good_matches\n",
    "    \n",
    "    def estimate_transform(self, kp1, kp2, matches, transform_type='homography'):\n",
    "        \"\"\"estimate transformation matrix from matched keypoints\"\"\"\n",
    "        if len(matches) < 4:\n",
    "            print(f\"‚ùå not enough matches ({len(matches)}) for transformation\")\n",
    "            return None\n",
    "            \n",
    "        # extract matched points\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        if transform_type == 'homography':\n",
    "            matrix, mask = cv2.findHomography(src_pts, dst_pts, \n",
    "                                            cv2.RANSAC, 5.0)\n",
    "        elif transform_type == 'affine':\n",
    "            matrix, mask = cv2.estimateAffinePartial2D(src_pts, dst_pts)\n",
    "        else:\n",
    "            print(f\"‚ùå unsupported transform type: {transform_type}\")\n",
    "            return None\n",
    "            \n",
    "        if matrix is None:\n",
    "            print(\"‚ùå failed to estimate transformation\")\n",
    "            return None\n",
    "            \n",
    "        # count inliers\n",
    "        inliers = np.sum(mask) if mask is not None else len(matches)\n",
    "        print(f\"‚úÖ transformation estimated with {inliers}/{len(matches)} inliers\")\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    def align_to_reference(self, images, reference_index=0, transform_type='homography'):\n",
    "        \"\"\"align all images to a reference image\"\"\"\n",
    "        if not images or len(images) < 2:\n",
    "            print(\"‚ùå need at least 2 images for alignment\")\n",
    "            return []\n",
    "            \n",
    "        reference_img = images[reference_index]\n",
    "        aligned_images = [reference_img.copy()]  # reference stays unchanged\n",
    "        transforms = [np.eye(3)]  # identity for reference\n",
    "        \n",
    "        print(f\"üéØ aligning {len(images)} images to reference (image {reference_index})\")\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            if i == reference_index:\n",
    "                continue\n",
    "                \n",
    "            print(f\"üîÑ aligning image {i}...\")\n",
    "            \n",
    "            # detect and match features\n",
    "            kp_ref, kp_img, matches = self.detect_and_match_features(reference_img, img)\n",
    "            \n",
    "            if len(matches) < 10:\n",
    "                print(f\"‚ö†Ô∏è  warning: only {len(matches)} matches found for image {i}\")\n",
    "            \n",
    "            # estimate transformation\n",
    "            transform_matrix = self.estimate_transform(kp_ref, kp_img, matches, transform_type)\n",
    "            \n",
    "            if transform_matrix is not None:\n",
    "                # apply transformation\n",
    "                h, w = reference_img.shape[:2]\n",
    "                if transform_type == 'homography':\n",
    "                    aligned_img = cv2.warpPerspective(img, transform_matrix, (w, h))\n",
    "                else:\n",
    "                    aligned_img = cv2.warpAffine(img, transform_matrix, (w, h))\n",
    "                    \n",
    "                aligned_images.insert(i, aligned_img)\n",
    "                transforms.insert(i, transform_matrix)\n",
    "                print(f\"‚úÖ image {i} aligned successfully\")\n",
    "            else:\n",
    "                print(f\"‚ùå failed to align image {i}, using original\")\n",
    "                aligned_images.insert(i, img.copy())\n",
    "                transforms.insert(i, np.eye(3))\n",
    "        \n",
    "        return aligned_images, transforms\n",
    "\n",
    "# add alignment functionality to processor\n",
    "def add_alignment_to_processor():\n",
    "    \"\"\"add alignment functionality to the main processor\"\"\"\n",
    "    \n",
    "    def align_images(self, reference_index=0, transform_type='homography'):\n",
    "        \"\"\"align all loaded images\"\"\"\n",
    "        if not self.images:\n",
    "            print(\"‚ùå no images loaded\")\n",
    "            return False\n",
    "            \n",
    "        aligner = ImageAligner()\n",
    "        \n",
    "        # apply crop if selected\n",
    "        images_to_align = self.images\n",
    "        if self.crop_box:\n",
    "            x1, y1, x2, y2 = self.crop_box\n",
    "            images_to_align = [img[y1:y2, x1:x2] for img in self.images]\n",
    "            print(f\"üîÑ applying crop ({x1},{y1}) to ({x2},{y2})\")\n",
    "        \n",
    "        aligned_imgs, transforms = aligner.align_to_reference(\n",
    "            images_to_align, reference_index, transform_type\n",
    "        )\n",
    "        \n",
    "        if aligned_imgs:\n",
    "            self.aligned_images = aligned_imgs\n",
    "            self.transforms = transforms\n",
    "            print(f\"‚úÖ aligned {len(aligned_imgs)} images successfully!\")\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    # add method to processor\n",
    "    NimsloProcessor.align_images = align_images\n",
    "\n",
    "add_alignment_to_processor()\n",
    "print(\"üß© image alignment functionality added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15305eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistogramMatcher:\n",
    "    \"\"\"handles histogram matching for consistent exposure across images\"\"\"\n",
    "    \n",
    "    def __init__(self, reference_index=0):\n",
    "        self.reference_index = reference_index\n",
    "    \n",
    "    def match_histogram(self, source, reference, multichannel=True):\n",
    "        \"\"\"match histogram of source image to reference image\"\"\"\n",
    "        if multichannel:\n",
    "            # process each channel separately for color images\n",
    "            matched = np.zeros_like(source)\n",
    "            for channel in range(source.shape[2]):\n",
    "                matched[:, :, channel] = self._match_histogram_single_channel(\n",
    "                    source[:, :, channel], reference[:, :, channel]\n",
    "                )\n",
    "            return matched\n",
    "        else:\n",
    "            return self._match_histogram_single_channel(source, reference)\n",
    "    \n",
    "    def _match_histogram_single_channel(self, source, reference):\n",
    "        \"\"\"match histogram for a single channel\"\"\"\n",
    "        # get histograms\n",
    "        source_hist, source_bins = np.histogram(source.flatten(), 256, density=True)\n",
    "        ref_hist, ref_bins = np.histogram(reference.flatten(), 256, density=True)\n",
    "        \n",
    "        # calculate cumulative distribution functions\n",
    "        source_cdf = source_hist.cumsum()\n",
    "        ref_cdf = ref_hist.cumsum()\n",
    "        \n",
    "        # normalize cdfs\n",
    "        source_cdf = source_cdf / source_cdf[-1]\n",
    "        ref_cdf = ref_cdf / ref_cdf[-1]\n",
    "        \n",
    "        # create lookup table\n",
    "        lookup_table = np.interp(source_cdf, ref_cdf, np.arange(256))\n",
    "        \n",
    "        # apply lookup table\n",
    "        matched = np.interp(source.flatten(), np.arange(256), lookup_table)\n",
    "        \n",
    "        return matched.reshape(source.shape).astype(source.dtype)\n",
    "    \n",
    "    def adaptive_histogram_match(self, source, reference, strength=0.7):\n",
    "        \"\"\"gentler histogram matching that preserves some original character\"\"\"\n",
    "        matched = self.match_histogram(source, reference)\n",
    "        \n",
    "        # blend original with matched version\n",
    "        result = (1 - strength) * source + strength * matched\n",
    "        \n",
    "        return result.astype(source.dtype)\n",
    "    \n",
    "    def match_exposure_stats(self, images, reference_index=0):\n",
    "        \"\"\"match basic exposure statistics (mean, std) across images\"\"\"\n",
    "        if not images:\n",
    "            return []\n",
    "            \n",
    "        reference = images[reference_index].astype(np.float32)\n",
    "        ref_mean = np.mean(reference)\n",
    "        ref_std = np.std(reference)\n",
    "        \n",
    "        matched_images = []\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            if i == reference_index:\n",
    "                matched_images.append(img)\n",
    "                continue\n",
    "                \n",
    "            img_float = img.astype(np.float32)\n",
    "            img_mean = np.mean(img_float)\n",
    "            img_std = np.std(img_float)\n",
    "            \n",
    "            # normalize and rescale\n",
    "            normalized = (img_float - img_mean) / (img_std + 1e-8)\n",
    "            rescaled = normalized * ref_std + ref_mean\n",
    "            \n",
    "            # clip to valid range\n",
    "            rescaled = np.clip(rescaled, 0, 255).astype(np.uint8)\n",
    "            matched_images.append(rescaled)\n",
    "            \n",
    "        return matched_images\n",
    "    \n",
    "    def visualize_histograms(self, images, titles=None):\n",
    "        \"\"\"visualize histograms of all images for comparison\"\"\"\n",
    "        n_images = len(images)\n",
    "        fig, axes = plt.subplots(2, n_images, figsize=(4*n_images, 8))\n",
    "        \n",
    "        if titles is None:\n",
    "            titles = [f\"image {i+1}\" for i in range(n_images)]\n",
    "        \n",
    "        colors = ['red', 'green', 'blue']\n",
    "        \n",
    "        for i, (img, title) in enumerate(zip(images, titles)):\n",
    "            # show image\n",
    "            axes[0, i].imshow(img)\n",
    "            axes[0, i].set_title(title)\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # show histogram\n",
    "            for channel, color in enumerate(colors):\n",
    "                hist, bins = np.histogram(img[:, :, channel], bins=256, range=(0, 256))\n",
    "                axes[1, i].plot(bins[:-1], hist, color=color, alpha=0.7, label=color)\n",
    "            \n",
    "            axes[1, i].set_title(f\"histogram - {title}\")\n",
    "            axes[1, i].set_xlim(0, 255)\n",
    "            axes[1, i].legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# add histogram matching to processor\n",
    "def add_histogram_matching_to_processor():\n",
    "    \"\"\"add histogram matching functionality to the main processor\"\"\"\n",
    "    \n",
    "    def match_histograms(self, reference_index=0, method='adaptive', strength=0.7):\n",
    "        \"\"\"match histograms of all images\"\"\"\n",
    "        if not self.aligned_images:\n",
    "            print(\"‚ùå no aligned images available - run alignment first\")\n",
    "            return False\n",
    "            \n",
    "        matcher = HistogramMatcher(reference_index)\n",
    "        \n",
    "        print(f\"üåà matching histograms using {method} method...\")\n",
    "        \n",
    "        if method == 'adaptive':\n",
    "            matched_images = []\n",
    "            reference = self.aligned_images[reference_index]\n",
    "            \n",
    "            for i, img in enumerate(self.aligned_images):\n",
    "                if i == reference_index:\n",
    "                    matched_images.append(img)\n",
    "                    print(f\"üìä image {i}: reference (unchanged)\")\n",
    "                else:\n",
    "                    matched = matcher.adaptive_histogram_match(img, reference, strength)\n",
    "                    matched_images.append(matched)\n",
    "                    print(f\"üìä image {i}: histogram matched (strength={strength})\")\n",
    "                    \n",
    "        elif method == 'full':\n",
    "            matched_images = []\n",
    "            reference = self.aligned_images[reference_index]\n",
    "            \n",
    "            for i, img in enumerate(self.aligned_images):\n",
    "                if i == reference_index:\n",
    "                    matched_images.append(img)\n",
    "                else:\n",
    "                    matched = matcher.match_histogram(img, reference)\n",
    "                    matched_images.append(matched)\n",
    "                    print(f\"üìä image {i}: full histogram matched\")\n",
    "                    \n",
    "        elif method == 'exposure':\n",
    "            matched_images = matcher.match_exposure_stats(self.aligned_images, reference_index)\n",
    "            print(\"üìä exposure statistics matched\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå unknown method: {method}\")\n",
    "            return False\n",
    "        \n",
    "        self.matched_images = matched_images\n",
    "        print(f\"‚úÖ histogram matching complete!\")\n",
    "        return True\n",
    "    \n",
    "    def show_histogram_comparison(self):\n",
    "        \"\"\"show before/after histogram comparison\"\"\"\n",
    "        if not self.aligned_images or not self.matched_images:\n",
    "            print(\"‚ùå need both aligned and matched images\")\n",
    "            return\n",
    "            \n",
    "        matcher = HistogramMatcher()\n",
    "        \n",
    "        print(\"üìä before histogram matching:\")\n",
    "        matcher.visualize_histograms(self.aligned_images, \n",
    "                                    [f\"aligned {i+1}\" for i in range(len(self.aligned_images))])\n",
    "        \n",
    "        print(\"üìä after histogram matching:\")\n",
    "        matcher.visualize_histograms(self.matched_images,\n",
    "                                   [f\"matched {i+1}\" for i in range(len(self.matched_images))])\n",
    "    \n",
    "    # add methods to processor\n",
    "    NimsloProcessor.match_histograms = match_histograms\n",
    "    NimsloProcessor.show_histogram_comparison = show_histogram_comparison\n",
    "\n",
    "add_histogram_matching_to_processor()\n",
    "print(\"üé® histogram matching functionality added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GifExporter:\n",
    "    \"\"\"handles creation and export of animated gifs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output_folder = \"nimslo_gifs\"\n",
    "        os.makedirs(self.output_folder, exist_ok=True)\n",
    "    \n",
    "    def create_gif(self, images, output_path, duration=0.2, loop=0, optimize=True):\n",
    "        \"\"\"create animated gif from list of images\"\"\"\n",
    "        if not images:\n",
    "            print(\"‚ùå no images to create gif from\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"üé¨ creating gif with {len(images)} frames...\")\n",
    "        \n",
    "        # convert numpy arrays to PIL images\n",
    "        pil_images = []\n",
    "        for i, img in enumerate(images):\n",
    "            if isinstance(img, np.ndarray):\n",
    "                # ensure uint8 format\n",
    "                if img.dtype != np.uint8:\n",
    "                    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "                pil_img = PILImage.fromarray(img)\n",
    "            else:\n",
    "                pil_img = img\n",
    "            pil_images.append(pil_img)\n",
    "            print(f\"‚úÖ frame {i+1} converted\")\n",
    "        \n",
    "        # save as gif\n",
    "        try:\n",
    "            pil_images[0].save(\n",
    "                output_path,\n",
    "                save_all=True,\n",
    "                append_images=pil_images[1:],\n",
    "                duration=int(duration * 1000),  # convert to milliseconds\n",
    "                loop=loop,\n",
    "                optimize=optimize\n",
    "            )\n",
    "            print(f\"üéâ gif saved to: {output_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå failed to save gif: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def create_comparison_gif(self, original_images, processed_images, output_path, \n",
    "                            duration=0.5, show_original_first=True):\n",
    "        \"\"\"create a comparison gif showing original vs processed\"\"\"\n",
    "        if len(original_images) != len(processed_images):\n",
    "            print(\"‚ùå mismatch in number of original vs processed images\")\n",
    "            return False\n",
    "        \n",
    "        comparison_frames = []\n",
    "        \n",
    "        for orig, proc in zip(original_images, processed_images):\n",
    "            if show_original_first:\n",
    "                comparison_frames.extend([orig, proc])\n",
    "            else:\n",
    "                comparison_frames.extend([proc, orig])\n",
    "        \n",
    "        return self.create_gif(comparison_frames, output_path, duration)\n",
    "    \n",
    "    def create_side_by_side_gif(self, images, output_path, duration=0.2):\n",
    "        \"\"\"create gif showing all frames side by side\"\"\"\n",
    "        if not images:\n",
    "            return False\n",
    "            \n",
    "        # calculate grid layout\n",
    "        n_images = len(images)\n",
    "        cols = min(4, n_images)\n",
    "        rows = (n_images + cols - 1) // cols\n",
    "        \n",
    "        # get dimensions\n",
    "        h, w = images[0].shape[:2]\n",
    "        grid_h = h * rows\n",
    "        grid_w = w * cols\n",
    "        \n",
    "        # create grid image\n",
    "        grid_img = np.zeros((grid_h, grid_w, 3), dtype=np.uint8)\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            row = i // cols\n",
    "            col = i % cols\n",
    "            y1, y2 = row * h, (row + 1) * h\n",
    "            x1, x2 = col * w, (col + 1) * w\n",
    "            grid_img[y1:y2, x1:x2] = img\n",
    "        \n",
    "        # create single frame gif (static comparison)\n",
    "        return self.create_gif([grid_img], output_path, duration=1.0)\n",
    "    \n",
    "    def preview_gif_frames(self, images, title=\"gif preview\"):\n",
    "        \"\"\"preview frames that will be in the gif\"\"\"\n",
    "        if not images:\n",
    "            print(\"‚ùå no images to preview\")\n",
    "            return\n",
    "            \n",
    "        n_images = len(images)\n",
    "        cols = min(4, n_images)\n",
    "        rows = (n_images + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 4*rows))\n",
    "        fig.suptitle(f\"{title} - {n_images} frames\", fontsize=16)\n",
    "        \n",
    "        if rows == 1 and cols == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1:\n",
    "            axes = [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "        for i, img in enumerate(images):\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"frame {i+1}\")\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        # hide unused subplots\n",
    "        for i in range(n_images, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# add gif export functionality to processor\n",
    "def add_gif_export_to_processor():\n",
    "    \"\"\"add gif export functionality to the main processor\"\"\"\n",
    "    \n",
    "    def create_nimslo_gif(self, output_filename=None, duration=0.15, preview=True):\n",
    "        \"\"\"create the final nimslo gif\"\"\"\n",
    "        if not self.matched_images:\n",
    "            print(\"‚ùå no processed images available - run full pipeline first\")\n",
    "            return False\n",
    "            \n",
    "        exporter = GifExporter()\n",
    "        \n",
    "        if output_filename is None:\n",
    "            timestamp = __import__('datetime').datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = f\"nimslo_{timestamp}.gif\"\n",
    "        \n",
    "        output_path = os.path.join(exporter.output_folder, output_filename)\n",
    "        \n",
    "        if preview:\n",
    "            print(\"üé¨ preview of final gif frames:\")\n",
    "            exporter.preview_gif_frames(self.matched_images, \"final nimslo gif\")\n",
    "        \n",
    "        success = exporter.create_gif(self.matched_images, output_path, duration)\n",
    "        \n",
    "        if success:\n",
    "            # show file info\n",
    "            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
    "            print(f\"üìÅ file size: {file_size:.2f} MB\")\n",
    "            print(f\"üéØ frames: {len(self.matched_images)}\")\n",
    "            print(f\"‚è±Ô∏è  duration per frame: {duration}s\")\n",
    "            \n",
    "            # display the gif in jupyter (if possible)\n",
    "            try:\n",
    "                from IPython.display import Image as IPImage\n",
    "                display(IPImage(output_path))\n",
    "            except:\n",
    "                print(\"üí° gif created but couldn't display inline - check output folder\")\n",
    "        \n",
    "        return success\n",
    "    \n",
    "    def create_comparison_gif(self, output_filename=None, duration=0.3):\n",
    "        \"\"\"create a before/after comparison gif\"\"\"\n",
    "        if not self.images or not self.matched_images:\n",
    "            print(\"‚ùå need both original and processed images\")\n",
    "            return False\n",
    "            \n",
    "        exporter = GifExporter()\n",
    "        \n",
    "        if output_filename is None:\n",
    "            timestamp = __import__('datetime').datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = f\"nimslo_comparison_{timestamp}.gif\"\n",
    "        \n",
    "        output_path = os.path.join(exporter.output_folder, output_filename)\n",
    "        \n",
    "        # use cropped originals if crop was applied\n",
    "        original_images = self.images\n",
    "        if self.crop_box:\n",
    "            x1, y1, x2, y2 = self.crop_box\n",
    "            original_images = [img[y1:y2, x1:x2] for img in self.images]\n",
    "        \n",
    "        return exporter.create_comparison_gif(\n",
    "            original_images, self.matched_images, output_path, duration\n",
    "        )\n",
    "    \n",
    "    def set_output_folder(self, folder_path):\n",
    "        \"\"\"set custom output folder for gifs\"\"\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        GifExporter().output_folder = folder_path\n",
    "        print(f\"üìÅ output folder set to: {folder_path}\")\n",
    "    \n",
    "    # add methods to processor\n",
    "    NimsloProcessor.create_nimslo_gif = create_nimslo_gif\n",
    "    NimsloProcessor.create_comparison_gif = create_comparison_gif\n",
    "    NimsloProcessor.set_output_folder = set_output_folder\n",
    "\n",
    "add_gif_export_to_processor()\n",
    "print(\"üé¨ gif export functionality added!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f83e1",
   "metadata": {},
   "source": [
    "## üöÄ usage guide\n",
    "\n",
    "now that we've built all the components, here's how to use the nimslo processor:\n",
    "\n",
    "### basic workflow:\n",
    "1. **load images**: `processor.load_images()` - select your nimslo batch folder\n",
    "2. **preview**: `processor.show_images()` - see what we're working with\n",
    "3. **crop & reference**: `processor.select_crop_and_reference()` - interactive gui selection\n",
    "4. **align**: `processor.align_images()` - computer vision magic\n",
    "5. **match histograms**: `processor.match_histograms()` - consistent exposure\n",
    "6. **create gif**: `processor.create_nimslo_gif()` - final output!\n",
    "\n",
    "### quick start:\n",
    "- run the cell below for an automated pipeline\n",
    "- or run each step individually for more control\n",
    "- all methods have helpful print statements so you know what's happening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676af240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé¨ DEMO TIME! \n",
    "# uncomment and run the lines below to process your nimslo batch\n",
    "\n",
    "# OPTION 1: fully automated pipeline\n",
    "# process_nimslo_batch(processor)\n",
    "\n",
    "# OPTION 2: step by step (more control)\n",
    "# processor.load_images()  # select your folder\n",
    "# processor.show_images()  # preview loaded images\n",
    "# processor.select_crop_and_reference()  # interactive gui\n",
    "# processor.align_images()  # computer vision alignment\n",
    "# processor.show_images(processor.aligned_images, \"aligned\")\n",
    "# processor.match_histograms(method='adaptive', strength=0.7)\n",
    "# processor.show_histogram_comparison()\n",
    "# processor.create_nimslo_gif(duration=0.15)\n",
    "\n",
    "# OPTION 3: quick test with different settings\n",
    "# processor.align_images(transform_type='affine')  # try affine vs homography\n",
    "# processor.match_histograms(method='exposure')    # try different matching methods\n",
    "# processor.create_nimslo_gif(duration=0.1)       # faster gif\n",
    "\n",
    "print(\"üéØ ready to process! uncomment the lines above to start\")\n",
    "print(\"üìÅ make sure you have your nimslo images in a folder\")\n",
    "print(\"üí° tip: the interactive cropping opens a matplotlib window\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0739a6e",
   "metadata": {},
   "source": [
    "## üí° tips & tricks\n",
    "\n",
    "### alignment methods:\n",
    "- **homography**: handles perspective changes, best for most nimslo shots\n",
    "- **affine**: simpler transformation, good for minimal camera movement\n",
    "\n",
    "### histogram matching options:\n",
    "- **adaptive**: gentler matching, preserves character (recommended)\n",
    "- **full**: complete histogram matching, more uniform look\n",
    "- **exposure**: basic stats matching, fastest processing\n",
    "\n",
    "### troubleshooting:\n",
    "- **few feature matches**: try different reference image or crop tighter\n",
    "- **misaligned results**: check reference points, try affine transform\n",
    "- **weird colors**: reduce histogram matching strength or try 'exposure' method\n",
    "- **large file sizes**: reduce image resolution before processing\n",
    "\n",
    "### future enhancements:\n",
    "- üß† cnn-based alignment using deep learning models\n",
    "- üé® advanced color grading and tone matching\n",
    "- üìê automatic crop detection using edge detection\n",
    "- üîÑ batch processing of multiple nimslo sets\n",
    "- üéõÔ∏è gui application with sliders for real-time adjustments\n",
    "\n",
    "---\n",
    "\n",
    "**made with ‚ù§Ô∏è  for analog photography lovers**  \n",
    "*enjoy creating those sweet 3d gifs!* üéâ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
